gpu_id: '0'
log_wandb: False


hidden_size: 64                 # (int) Number of features in the hidden state. 
n_layers: 1                   # (int) Number of Mamba layers.
loss_type: 'CE'                 # (str) Type of loss function. Range in ['BPR', 'CE'].
  
d_state: 32                     # (int) SSM state expansion factor
d_conv: 4                       # (int) Local convolution width
expand: 2                # (int) Block expansion factor
n_heads: 1
hidden_act: 'gelu'              # (str) The activation function in feed-forward layer.


dropout_prob: 0.4   
attn_dropout_prob: 0.4
hidden_dropout_prob: 0.4



MAX_ITEM_LIST_LENGTH: 50    # 50 for Amazon datasets

USER_ID_FIELD: user_id
ITEM_ID_FIELD: item_id
load_col:
    inter: [user_id, item_id, timestamp]
    


user_inter_num_interval: "[5,inf)"
item_inter_num_interval: "[5,inf)"

# training settings
epochs: 300
train_batch_size: 2048
learner: adam
learning_rate: 0.001
eval_step: 1
stopping_step: 10
train_neg_sample_args: ~
initializer_range: 0.02         # (float) The standard deviation for normal initialization.
# evalution settings
metrics: ["Recall","NDCG","MRR"]
topk: [1,5,10,20]
valid_metric: NDCG@10
eval_batch_size: 4096
weight_decay: 0.0

